{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activity 2.4\n",
    "Here's a far more independent task, a big \"step up\" from previous tasks as you will have to do some searching for answers on how best complete it. The Wisconsin Breast Cancer dataset is another benchmark dataset for machine learning tasks. Find and download the datasets from this repository: http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29 (you will need the wdbc files and not the wpbc files) and train and test a classification model(s) for this data. (You will need to look up how to parse and preprocess some of the data!). Record your metric for your best model.\n",
    "\n",
    "Now answer the following questions:\n",
    "\n",
    "Can you think of a few ways of how this model might not be appropriate, or poorly implemented in practice? For example, how would two patients, one with a tumour \"on the border\" of being malignant, and one with a tumour \"safely\" benign be classified by our model? Is this correct? Can you think of any adjustments to the algorithm or model that might help remedy this?\n",
    "Try to explain the real-life impact of differing hyperparameters - for example, differing values of  ùëò  for kNN, or different kernels for SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required data.\n",
    "raw_data = pd.read_csv(\"breast-cancer-wisconsin.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we need to have a look at what the file contains and how its structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   id                 699 non-null    int64 \n",
      " 1   clump_thickness    699 non-null    int64 \n",
      " 2   size_uniformity    699 non-null    int64 \n",
      " 3   shape_uniformity   699 non-null    int64 \n",
      " 4   marginal_adhesion  699 non-null    int64 \n",
      " 5   epithelial_size    699 non-null    int64 \n",
      " 6   bare_nucleoli      699 non-null    object\n",
      " 7   bland_chromatin    699 non-null    int64 \n",
      " 8   normal_nucleoli    699 non-null    int64 \n",
      " 9   mitoses            699 non-null    int64 \n",
      " 10  class              699 non-null    int64 \n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 60.2+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "line 7 indicates \"object\" where all other cols report int64\n",
    "lets find out the scale of this issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row number is  23    object is  ?\n",
      "Row number is  40    object is  ?\n",
      "Row number is  139    object is  ?\n",
      "Row number is  145    object is  ?\n",
      "Row number is  158    object is  ?\n",
      "Row number is  164    object is  ?\n",
      "Row number is  235    object is  ?\n",
      "Row number is  249    object is  ?\n",
      "Row number is  275    object is  ?\n",
      "Row number is  292    object is  ?\n",
      "Row number is  294    object is  ?\n",
      "Row number is  297    object is  ?\n",
      "Row number is  315    object is  ?\n",
      "Row number is  321    object is  ?\n",
      "Row number is  411    object is  ?\n",
      "Row number is  617    object is  ?\n",
      "Number of rows  16\n"
     ]
    }
   ],
   "source": [
    "#So process the col and count how many rows concerned have a non mumeric cell\n",
    "count = 0\n",
    "for i in range(699):\n",
    "    #If cell contains an object report the object and row\n",
    "    test = raw_data[\"bare_nucleoli\"][i]\n",
    "    if test.isnumeric()==False:\n",
    "        print(\"Row number is \",i, \"   object is \",raw_data[\"bare_nucleoli\"][i])\n",
    "        count=count+1\n",
    "        #Counting the number of rows involved\n",
    "print(\"Number of rows \",count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the data set contains 699 rows in which one column (\"bare_nucleoli\") returns numeric informatation but also 16 cells containing '?'.\n",
    "If we delete this column we lose 699 - 16 data points i.e. 683, if we delete the People row we lose 16 data row points.\n",
    "Our do we enter something value in its place?\n",
    "Dealing with missing data. On doing a Tally, 403 cells contain the value 1, 132 cells contain the value 8 so, I will use 1 as replacement. This decision should be reviwed in greater depth before final decision is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now replace ? with 1, again what seems a simple thing it woun't do it, so I updated the file manually\n",
    "count = 0\n",
    "for i in range(699):\n",
    "      if raw_data[\"bare_nucleoli\"][i]=='?':\n",
    "        raw_data[\"bare_nucleoli\"][i]==1\n",
    "        count=count+1      \n",
    "print(\"Number of rows \",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_data = pd.read_csv(\"breast-cancer-wisconsin_1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   id                 699 non-null    int64 \n",
      " 1   clump_thickness    699 non-null    int64 \n",
      " 2   size_uniformity    699 non-null    int64 \n",
      " 3   shape_uniformity   699 non-null    int64 \n",
      " 4   marginal_adhesion  699 non-null    int64 \n",
      " 5   epithelial_size    699 non-null    int64 \n",
      " 6   bare_nucleoli      699 non-null    object\n",
      " 7   bland_chromatin    699 non-null    int64 \n",
      " 8   normal_nucleoli    699 non-null    int64 \n",
      " 9   mitoses            699 non-null    int64 \n",
      " 10  class              699 non-null    int64 \n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 60.2+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exclude the first and last column, the ID is nor required by us, and the last column id the coded outcomes\n",
    "columns = list(raw_data.columns[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now I will apply the three classifier learned on this course so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the function train_test_split to split the data randomly (random_state = 42) into a train and a test set. The test set will correspond to 20% of the total data (test_size = 0.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select our X and y data\n",
    "X = raw_data.loc[:,columns] #Assigned above\n",
    "y = raw_data.loc[:, 'class'] #Coded outcomes\n",
    "#Now split the training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we will use the SVC Classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "accuracy_all=[]\n",
    "cvs_all = []\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "accuracy_all.append(accuracy_score(prediction, y_test))\n",
    "cvs_all.append(np.mean(scores))\n",
    "\n",
    "print(\"SVC Accuracy: {0:.2%}\".format(accuracy_score(prediction, y_test)))\n",
    "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(scores), np.std(scores)*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now try the KNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model1 = KNeighborsClassifier()\n",
    "model1.fit(X_train, y_train)\n",
    "prediction = model1.predict(X_test)\n",
    "scores = cross_val_score(model1, X, y, cv=5)\n",
    "\n",
    "accuracy_all.append(accuracy_score(prediction, y_test))\n",
    "cvs_all.append(np.mean(scores))\n",
    "\n",
    "print(\"Accuracy: {0:.2%}\".format(accuracy_score(prediction, y_test)))\n",
    "print(\"Cross validation score: {0:.2%} (+/- {1:.2%})\".format(np.mean(scores), np.std(scores)*2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "#Take the inward dataset and try different numbers of clusters\n",
    "#We are doing scoring of each number of clusters\n",
    "scores = []\n",
    "trial_num_clus = 11\n",
    "for i in range(1,trial_num_clus ):\n",
    "    model2 = KMeans(n_clusters=i) #So we are running i clusters\n",
    "    model2.fit(X_train, y_train)\n",
    "    \n",
    "    # Score the model\n",
    "    scores.append(model2.score(X_train, y_train))\n",
    "    \n",
    "#Now plot the results, which number of clusters causes the greatest change in gradient\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "ax.plot(list(range(1,trial_num_clus)), scores)\n",
    "\n",
    "ax.set_xlabel(\"Value of k\")\n",
    "ax.set_ylabel(\"Score (higher is better)\")\n",
    "ax.set_title(\"Score of different K Means Clustering models based on different values of K\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create an instance of KMeans Classifier and fit the data.\n",
    "model3 = KMeans(n_clusters=4)\n",
    "model3.fit(X)\n",
    "\n",
    "y_pred = model3.predict(X)\n",
    "\n",
    "prediction = model3.predict(X_test)\n",
    "\n",
    "scores = cross_val_score(model3, X, y, cv=5)\n",
    "\n",
    "\n",
    "accuracy_all.append(accuracy_score(prediction, y_test))\n",
    "cvs_all.append(np.mean(scores))\n",
    "\n",
    "print(\"Accuracy: {0:.2%}\".format(accuracy_score(prediction, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN gave the best result at 98.57%, SVC and other kernals (now removed) did slightly less at approx. 97.14%\n",
    "KMeans 71%.\n",
    "\n",
    "This software application is used to read images from a medical screening device and classify them, where in the past humans would have had to look and classify these images. The results from the above investigation would suggest an accuracy of 99% for the SVM algorithm, so two people in one hundred could get a false result. However, the accuracy rate for a human reader is 69%, with software having many benefits over humans, especially, it will carry out the classification consistently  every hour of the day, in fact 24 hours a day, plus many other advantages must go in favour of the algorithm.\n",
    "\n",
    "Here we are talking of false negatives and false positives, so a criterion should be established where the humans keep a quality check on the scans closer to the decision edge. In addition, a control charting process would be advisable to alert the operators if decisions from the software are going close to boundary run rates. So I would suggest that the marginal scan decisions are monitored by qualified humans in order to set confidence levels. \n",
    "\n",
    "Only three algorithms were checked in this study, SVM, KNN and KMeans however there maybe other more appropriate algorithms that still need to be tested. \n",
    "The algorithms tested showed significant improvements over humans and with additional controls in place that most likely are not in place for humans would add more credibility to the scan outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
